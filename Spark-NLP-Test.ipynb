{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import sys\n",
    "import datetime\n",
    "sys.path.append('../../')\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.common import RegexRule\n",
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from pyspark.sql.functions import explode\n",
    "\n",
    "from dateutil.parser import parse\n",
    "# for tokenizing\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# for schema\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a spark context object\n",
    "appname= \"large_read_tar\"\n",
    "master=\"local\"\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.appName(appname)\\\n",
    "                .config(\"spark.cassandra.connection.host\", \"localhost\")\\\n",
    "                .config(\"spark.cassandra.connection.port\", \"9042\")\\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_path = 's3a://twitter-data-dump/test.tar'\n",
    "trump_json = 's3a://twitter-data-dump/celebrities/trump.json'\n",
    "#large_tar = 's3a://twitter-data-dump/zip_dump/archiveteam-twitter-stream-2013-09.tar'\n",
    "small_portion = 's3a://twitter-data-dump/smallportion/'\n",
    "\n",
    "\n",
    "df = spark.read.json(small_portion)\n",
    "df_trump = spark.read.json(trump_json)\n",
    "\n",
    "resource_path ='/home/ubuntu/Desktop/spark-nlp/src/test/resources/'\n",
    "#type(data) --> data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- contributors: string (nullable = true)\n",
      " |-- coordinates: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- delete: struct (nullable = true)\n",
      " |    |-- status: struct (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |-- user_id: long (nullable = true)\n",
      " |    |    |-- user_id_str: string (nullable = true)\n",
      " |-- entities: struct (nullable = true)\n",
      " |    |-- hashtags: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- text: string (nullable = true)\n",
      " |    |-- media: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- symbols: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- urls: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- url: string (nullable = true)\n",
      " |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |-- screen_name: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- favorited: boolean (nullable = true)\n",
      " |-- filter_level: string (nullable = true)\n",
      " |-- geo: struct (nullable = true)\n",
      " |    |-- coordinates: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- id_str: string (nullable = true)\n",
      " |-- in_reply_to_screen_name: string (nullable = true)\n",
      " |-- in_reply_to_status_id: long (nullable = true)\n",
      " |-- in_reply_to_status_id_str: string (nullable = true)\n",
      " |-- in_reply_to_user_id: long (nullable = true)\n",
      " |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |-- lang: string (nullable = true)\n",
      " |-- place: struct (nullable = true)\n",
      " |    |-- attributes: struct (nullable = true)\n",
      " |    |    |-- street_address: string (nullable = true)\n",
      " |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- country: string (nullable = true)\n",
      " |    |-- country_code: string (nullable = true)\n",
      " |    |-- full_name: string (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- place_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |-- possibly_sensitive: boolean (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- retweeted: boolean (nullable = true)\n",
      " |-- retweeted_status: struct (nullable = true)\n",
      " |    |-- contributors: string (nullable = true)\n",
      " |    |-- coordinates: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- entities: struct (nullable = true)\n",
      " |    |    |-- hashtags: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- text: string (nullable = true)\n",
      " |    |    |-- media: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- symbols: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- urls: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- user_mentions: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- id: long (nullable = true)\n",
      " |    |    |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |    |    |-- name: string (nullable = true)\n",
      " |    |    |    |    |-- screen_name: string (nullable = true)\n",
      " |    |-- favorite_count: long (nullable = true)\n",
      " |    |-- favorited: boolean (nullable = true)\n",
      " |    |-- geo: struct (nullable = true)\n",
      " |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_screen_name: string (nullable = true)\n",
      " |    |-- in_reply_to_status_id: long (nullable = true)\n",
      " |    |-- in_reply_to_status_id_str: string (nullable = true)\n",
      " |    |-- in_reply_to_user_id: long (nullable = true)\n",
      " |    |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- place: struct (nullable = true)\n",
      " |    |    |-- bounding_box: struct (nullable = true)\n",
      " |    |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- country: string (nullable = true)\n",
      " |    |    |-- country_code: string (nullable = true)\n",
      " |    |    |-- full_name: string (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- place_type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |-- possibly_sensitive: boolean (nullable = true)\n",
      " |    |-- retweet_count: long (nullable = true)\n",
      " |    |-- retweeted: boolean (nullable = true)\n",
      " |    |-- scopes: struct (nullable = true)\n",
      " |    |    |-- followers: boolean (nullable = true)\n",
      " |    |-- source: string (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- truncated: boolean (nullable = true)\n",
      " |    |-- user: struct (nullable = true)\n",
      " |    |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |    |-- created_at: string (nullable = true)\n",
      " |    |    |-- default_profile: boolean (nullable = true)\n",
      " |    |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |    |-- description: string (nullable = true)\n",
      " |    |    |-- favourites_count: long (nullable = true)\n",
      " |    |    |-- follow_request_sent: string (nullable = true)\n",
      " |    |    |-- followers_count: long (nullable = true)\n",
      " |    |    |-- following: string (nullable = true)\n",
      " |    |    |-- friends_count: long (nullable = true)\n",
      " |    |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |-- is_translator: boolean (nullable = true)\n",
      " |    |    |-- lang: string (nullable = true)\n",
      " |    |    |-- listed_count: long (nullable = true)\n",
      " |    |    |-- location: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |    |-- notifications: string (nullable = true)\n",
      " |    |    |-- profile_background_color: string (nullable = true)\n",
      " |    |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |    |-- profile_image_url: string (nullable = true)\n",
      " |    |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |    |-- profile_link_color: string (nullable = true)\n",
      " |    |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |    |-- profile_text_color: string (nullable = true)\n",
      " |    |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |    |-- protected: boolean (nullable = true)\n",
      " |    |    |-- screen_name: string (nullable = true)\n",
      " |    |    |-- statuses_count: long (nullable = true)\n",
      " |    |    |-- time_zone: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |    |    |-- utc_offset: long (nullable = true)\n",
      " |    |    |-- verified: boolean (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- truncated: boolean (nullable = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- default_profile: boolean (nullable = true)\n",
      " |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- favourites_count: long (nullable = true)\n",
      " |    |-- follow_request_sent: string (nullable = true)\n",
      " |    |-- followers_count: long (nullable = true)\n",
      " |    |-- following: string (nullable = true)\n",
      " |    |-- friends_count: long (nullable = true)\n",
      " |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- is_translator: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- listed_count: long (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- notifications: string (nullable = true)\n",
      " |    |-- profile_background_color: string (nullable = true)\n",
      " |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |-- profile_image_url: string (nullable = true)\n",
      " |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |-- profile_link_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |-- profile_text_color: string (nullable = true)\n",
      " |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |-- protected: boolean (nullable = true)\n",
      " |    |-- screen_name: string (nullable = true)\n",
      " |    |-- statuses_count: long (nullable = true)\n",
      " |    |-- time_zone: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- utc_offset: long (nullable = true)\n",
      " |    |-- verified: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tid: long (nullable = true)\n",
      " |-- uid: long (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- creation_time: string (nullable = true)\n",
      " |-- time_zone: string (nullable = true)\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- media_ary: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- hashtag_ary: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select interested col attributes\n",
    "main_df = df.selectExpr('id AS tid',\\\n",
    "                        'user.id AS uid',\\\n",
    "                        'text AS tweet',\\\n",
    "                        'user.created_at AS creation_time',\\\n",
    "                        'user.time_zone AS time_zone',\\\n",
    "                        'user.followers_count AS followers_count',\\\n",
    "                        'user.friends_count AS friends_count',\\\n",
    "                        'place.name AS city_name',\\\n",
    "                        'place.country AS country_name',\\\n",
    "                        'entities.media.media_url AS media_ary',\\\n",
    "                        'entities.hashtags.text AS hashtag_ary',\\\n",
    "                        'retweet_count',\\\n",
    "                        'favorite_count'                        \n",
    "                       ).where('tid is NOT NULL AND uid is NOT NULL')\n",
    "\n",
    "main_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tid: long (nullable = true)\n",
      " |-- uid: long (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- creation_time: string (nullable = true)\n",
      " |-- time_zone: string (nullable = true)\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- media_ary: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- hashtag_ary: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main DF column name set\n",
    "col_exp_set = ['tid','uid','tweet','creation_time',\n",
    "               'time_zone','followers_count',\n",
    "               'friends_count','city_name','country_name',\n",
    "               'media_ary','hashtag_ary','retweet_count',\n",
    "               'favorite_count',\n",
    "              ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(tid=362814954803433472, uid=194531988, tweet=u'Psalm 119:133', creation_time=u'Fri Sep 24 11:04:40 +0000 2010', time_zone=u'London', followers_count=140, friends_count=204, city_name=None, country_name=None, media_ary=None, hashtag_ary=[], retweet_count=0, favorite_count=0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_rdd = main_df.rdd\n",
    "base_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return 2 items: sentence_count,  <word_tuple>\n",
    "def process_tweet(description):\n",
    "    # base case\n",
    "    if description is None or description == \"\":\n",
    "        return (0,[])\n",
    "\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_list = []\n",
    " \n",
    "    words = tokenizer.tokenize(description)\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            word_list.append(stemmer.stem(w.lower()))\n",
    "\n",
    "    return (len(sent_tokenize(description)),word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse twitter time string to (date_str, timestamp_str, hour int)\n",
    "# note later only timestamp_str is changed to asTYpe\n",
    "def parse_time(creation_time):  \n",
    "    # fcn that converts dt to date-str and time-str\n",
    "    def cassandra_convert(dt):\n",
    "        hour = dt.strftime(\"%H\")\n",
    "        return (str(dt.date()), str(dt),int(hour))\n",
    "    \n",
    "    dt = None\n",
    "    try:\n",
    "        dt = parse(creation_time)\n",
    "    except Exception as e:\n",
    "        # 1. log and \n",
    "        # 2.use current system time instead\n",
    "        dt = datetime.datetime.now()\n",
    "    return cassandra_convert(dt)\n",
    "\n",
    "# Mapping: 1. 13 cols to 15 cols (word_list, date, \n",
    "#          timestamp, hour)\n",
    "#          2. (media_ary-> media_attached; tag_ary -> tag_count)\n",
    "def map_row(row):\n",
    "    # return if image attached\n",
    "    def check_image(media_ary):\n",
    "        if media_ary is None or\\\n",
    "           len(media_ary) == 0:\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "    # count # of hashtags\n",
    "    def count_tag(tag_ary):\n",
    "        if tag_ary is None:\n",
    "            return 0\n",
    "        return len(tag_ary)\n",
    "    \n",
    "    # create a list of tuples: [(str1, like_num),] or [(str1, ret_num)] \n",
    "    def create_tuple_list(vector, num):\n",
    "        result = [num]\n",
    "        for item in vector:\n",
    "            result.append(item)\n",
    "        if len(result) == 0:\n",
    "            return []\n",
    "        return result\n",
    "        \n",
    "    try:       \n",
    "        tid = row.tid\n",
    "        uid = row.uid\n",
    "        tweet = row.tweet\n",
    "        retweet_count = row.retweet_count\n",
    "        favorite_count = row.favorite_count\n",
    "        # Map token: sentence_count, word_list\n",
    "        sentence_count, word_list\\\n",
    "            = process_tweet(tweet)\n",
    "        # Map Time\n",
    "        creation_time = row.creation_time\n",
    "        date, timestamp, hour\\\n",
    "            = parse_time(creation_time)\n",
    "        time_zone = row.time_zone\n",
    "        followers_count = row.followers_count\n",
    "        friends_count = row.friends_count\n",
    "        city_name = row.city_name\n",
    "        country_name = row.country_name\n",
    "        media_ary = row.media_ary\n",
    "        # boolean\n",
    "        media_attached = check_image(media_ary)        \n",
    "        hashtag_ary = row.hashtag_ary\n",
    "        # count tags\n",
    "        tag_count = count_tag(hashtag_ary)\n",
    "                \n",
    "    except Exception as e:\n",
    "        # 1. log e and 2.return default        \n",
    "        return Row(tid=-1, uid=-1,\n",
    "            followers_count=-1,\n",
    "            friends_count=-1,\n",
    "            tweet='n/a',retweet_count=-1,\n",
    "            favorite_count=-1,sentence_count=-1,\n",
    "            word_list=[],\n",
    "            phrase_list=['n/a'],\n",
    "            date='2000-1-1',timestamp='00:00:00',hour=0,\n",
    "            time_zone='n/a',city_name='n/a',\n",
    "            country_name='n/a',\n",
    "            media_attached=False,tag_count=tag_count\n",
    "            )\n",
    "    \n",
    "    r = Row(tid=tid, uid=uid,\n",
    "            followers_count=followers_count,\n",
    "            friends_count=friends_count,\n",
    "            tweet=tweet,retweet_count=retweet_count,\n",
    "            favorite_count=favorite_count,sentence_count=sentence_count,\n",
    "            word_list=word_list,\n",
    "            phrase_list=['n/a'],\n",
    "            date=date,timestamp=timestamp,hour=hour,\n",
    "            time_zone=time_zone,city_name=city_name,\n",
    "            country_name=country_name,\n",
    "            media_attached=media_attached,tag_count=tag_count\n",
    "            )\n",
    "    return r \n",
    "    \n",
    "base_map_rdd = base_rdd.map(map_row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(city_name=None, country_name=None, date='2010-09-24', favorite_count=0, followers_count=140, friends_count=204, hour=11, media_attached=False, phrase_list=['n/a'], retweet_count=0, sentence_count=1, tag_count=0, tid=362814954803433472, time_zone=u'London', timestamp='2010-09-24 11:04:40+00:00', tweet=u'Psalm 119:133', uid=194531988, word_list=[u'psalm', u'119', u'133'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main DF column name set\n",
    "col_exp_set = ['tid','uid','tweet','followers_count',\n",
    "               'friends_count','retweet_count',\n",
    "               'favorite_count','sentence_count',\n",
    "               'word_list',\n",
    "               'phrase_rt',\n",
    "               'date','timestamp','hour',\n",
    "               'time_zone','city_name','country_name',\n",
    "               'media_attached','tag_count'\n",
    "              ]\n",
    "# Sanity Check\n",
    "r = base_map_rdd.take(1)[0]\n",
    "r\n",
    "# len(col_exp_set) --> 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Stage 1\n",
    "\n",
    "# Result type: (arg1={(k1,c1),(k2, c2)}, arg2=total_tweets)\n",
    "# mapping function for bm_rdd, \n",
    "def seqOp(result, row):\n",
    "    word_list = row[17]\n",
    "    fav_count = row[3]\n",
    "    retweet_count = row[9]\n",
    "    \n",
    "    # sanity check for word_list_fav could be empty\n",
    "    if len(word_list_fav) > 0:\n",
    "        \n",
    "\n",
    "    \n",
    "    # increment tweet count\n",
    "    result[1] + 1\n",
    "    return result\n",
    "\n",
    "# aggregate each partition, p1 refers to partition result\n",
    "def comOp(p1, p2):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2\n",
    "# Mapping function that sorts the results: easier to do final sort \n",
    "# instead of local sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute when group by uid with bm_rdd \n",
    "def compute_uid(bm_rdd):\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ary_type(col_name, col_type):\n",
    "    return StructField(col_name, ArrayType(StringType(), containsNull=True), True)\n",
    "# build the table schema\n",
    "def build_schema():\n",
    "    schema = \\\n",
    "    StructType([\n",
    "        StructField(\"city_name\",StringType(), True),\n",
    "        StructField(\"country_name\",StringType(), True),\n",
    "        StructField(\"creation_date\",StringType(), True),\n",
    "        StructField(\"creation_hour\",IntegerType(), True),         \n",
    "        StructField(\"creation_timestamp\",StringType(), True),       \n",
    "        StructField(\"followers_count\",IntegerType(), True),\n",
    "        StructField(\"friends_count\",IntegerType(), True),\n",
    "        StructField(\"hashtag_count\",IntegerType(), True),\n",
    "        StructField(\"media_attached\",BooleanType(), False),\n",
    "        StructField(\"phrase_token\",ArrayType(StringType(), containsNull=True),\n",
    "                    True),        \n",
    "        StructField(\"sentence_count\",IntegerType(), True),         \n",
    "        StructField(\"tid\",LongType(), False),  \n",
    "        StructField(\"time_zone\",StringType(), True),         \n",
    "        StructField(\"tweet\",StringType(), True),\n",
    "        StructField(\"uid\",LongType(), False),\n",
    "        StructField(\"word_token_set\",ArrayType(StringType(), containsNull=True),\n",
    "                    True),                     \n",
    "    ])\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- creation_date: string (nullable = true)\n",
      " |-- creation_hour: integer (nullable = true)\n",
      " |-- creation_timestamp: string (nullable = true)\n",
      " |-- followers_count: integer (nullable = true)\n",
      " |-- friends_count: integer (nullable = true)\n",
      " |-- hashtag_count: integer (nullable = true)\n",
      " |-- media_attached: boolean (nullable = false)\n",
      " |-- phrase_token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- sentence_count: integer (nullable = true)\n",
      " |-- tid: long (nullable = false)\n",
      " |-- time_zone: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- uid: long (nullable = false)\n",
      " |-- word_token_set: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fit rdd with schema\n",
    "schema = build_schema()\n",
    "df_uncasted = spark.createDataFrame(base_map_rdd, schema)\n",
    "df_uncasted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(city_name=None, country_name=None, creation_date=u'2010-09-24', creation_hour=11, creation_timestamp=u'2010-09-24 11:04:40+00:00', followers_count=140, friends_count=204, hashtag_count=0, media_attached=False, phrase_token=[u'n/a'], sentence_count=1, tid=362814954803433472, time_zone=u'London', tweet=u'Psalm 119:133', uid=194531988, word_token_set=[u'psalm', u'119', u'133'])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uncasted.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- creation_date: string (nullable = true)\n",
      " |-- creation_hour: integer (nullable = true)\n",
      " |-- creation_timestamp: timestamp (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- followers_count: integer (nullable = true)\n",
      " |-- friends_count: integer (nullable = true)\n",
      " |-- hashtag_count: integer (nullable = true)\n",
      " |-- media_attached: boolean (nullable = false)\n",
      " |-- phrase_token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- sentence_count: integer (nullable = true)\n",
      " |-- tid: long (nullable = false)\n",
      " |-- time_zone: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- uid: long (nullable = false)\n",
      " |-- word_token_set: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final = df_uncasted.select('creation_date',\n",
    "                              'creation_hour',\n",
    "                              df_uncasted.creation_timestamp.astype(TimestampType()),\n",
    "                              'city_name',\n",
    "                              'country_name',\n",
    "                              'followers_count',\n",
    "                              'friends_count',\n",
    "                              'hashtag_count',\n",
    "                              'media_attached',\n",
    "                              'phrase_token',\n",
    "                              'sentence_count',\n",
    "                              'tid',\n",
    "                              'time_zone',\n",
    "                              'tweet',\n",
    "                              'uid',\n",
    "                              'word_token_set'\n",
    "                             )\n",
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.take(1)\n",
    "\n",
    "part = df_final.limit(100)\n",
    "type(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "part.write.format(\"org.apache.spark.sql.cassandra\").\\\n",
    "            mode('append').options(table='b0',keyspace='twitter').save() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_frame(df, table_name):\n",
    "    df.write.format(\"org.apache.spark.sql.cassandra\").\\\n",
    "            mode('append').options(table=table_name,keyspace='twitter').save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data_frame(df_final,'b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(city_name=None, country_name=None, creation_date='2012-11-02', creation_hour=21, creation_timestamp='2012-11-02 21:07:21+00:00', followers_count=199, friends_count=147, hashtag_count=0, media_attached=False, phrase_token=['n/a'], sentence_count=1, tid=362814954803429378, time_zone=u'Pacific Time (US & Canada)', tweet=u\"so i want to pee but my dog fell asleep on my lap and she looks so cute and i don't want to wake her, ugh the struggle\", uid=921796843, word_token_set=[u'want', u'pee', u'dog', u'fell', u'asleep', u'lap', u'look', u'cute', u'want', u'wake', u'ugh', u'struggl'])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Region to parse and count words! ==> start from base_map_rdd\n",
    "# Region to parse and count words! ==> start from base_map_rdd\n",
    "# Region to parse and count words! ==> start from base_map_rdd\n",
    "# Region to parse and count words! ==> start from base_map_rdd\n",
    "# Region to parse and count words! ==> start from base_map_rdd\n",
    "base_map_rdd.take(2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city_name=None, country_name=None, creation_date='2010-09-24', creation_hour=11, creation_timestamp='2010-09-24 11:04:40+00:00', followers_count=140, friends_count=204, hashtag_count=0, media_attached=False, phrase_token=['n/a'], sentence_count=1, tid=362814954803433472, time_zone=u'London', tweet=u'Psalm 119:133', uid=194531988, word_token_set=[u'psalm', u'119', u'133'])]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(base_map_rdd)\n",
    "base_map_rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- creation_date: string (nullable = true)\n",
      " |-- creation_hour: long (nullable = true)\n",
      " |-- creation_timestamp: string (nullable = true)\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- hashtag_count: long (nullable = true)\n",
      " |-- media_attached: boolean (nullable = true)\n",
      " |-- phrase_token: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- sentence_count: long (nullable = true)\n",
      " |-- tid: long (nullable = true)\n",
      " |-- time_zone: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- uid: long (nullable = true)\n",
      " |-- word_token_set: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fcn that get uid\n",
    "def get_uid(bmrdd_row):\n",
    "        pass\n",
    "# pipedlined rdd -> df -> rdd (work around for now)  \n",
    "bm_rdd = base_map_rdd.toDF().rdd\n",
    "base_map_rdd.toDF().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RDD' object has no attribute 'printSchema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-1c7cbf048d5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RDD' object has no attribute 'printSchema'"
     ]
    }
   ],
   "source": [
    "# map each token as a tuple \n",
    "def map_token_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrach Space: Previous Tests and Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# filter and return list of lower cased words \n",
    "def clean_stem_tweet(description):\n",
    "    # base case\n",
    "    if description is None or description == \"\":\n",
    "        return []\n",
    "\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    word_list = []\n",
    "    words = tokenizer.tokenize(description)\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            word_list.append(stemmer.stem(w.lower()))\n",
    "            \n",
    "    return word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'all', u'work', u'play', u'make', u'jack', u'dull', u'boy', u'all', u'work', u'play', u'make', u'jack', u'dull', u'boy']\n",
      "1\n",
      "('phrases', ['data'])\n",
      "('words:', ['All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'dull', 'boy', '.', 'All', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', '.'])\n"
     ]
    }
   ],
   "source": [
    "data = \"All work and no play makes jack dull boy. All work and no play makes jack a dull boy.\"\n",
    "\n",
    "r = clean_stem_tweet(data)\n",
    "print(r)\n",
    "phrases = sent_tokenize('data')\n",
    "print(len(phrases))\n",
    "words = word_tokenize(data)\n",
    " \n",
    "print('phrases', phrases)\n",
    "\n",
    "print(\"words:\" , words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = [1, 2, 3, 4, 5]\n",
    "# distData = sc.parallelize(data)\n",
    "# type(distData)\n",
    "# distData.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2010, 9, 24, 11, 4, 40, tzinfo=tzlocal())"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.parser import parse\n",
    "import datetime\n",
    "\n",
    "# parse twitter time string to (y-m-d,h-m-s)\n",
    "def parse_time(creation_time):    \n",
    "    # fcn that converts dt to date-str and time-str\n",
    "    def cassandra_convert(dt):\n",
    "        time = dt.strftime(\"%H:%M:%S\")\n",
    "        return (str(dt.date()), time)\n",
    "    try:\n",
    "        dt = parse(creation_time)\n",
    "    except Exception as e:\n",
    "        # 1. log and \n",
    "        # 2.use current system time instead\n",
    "        dt = datetime.datetime.now()\n",
    "    return cassandra_convert(dt)\n",
    "\n",
    "# rez = None\n",
    "# creation_time = u'Fri Sep 24 11:04:40 +0000 2010'\n",
    "# try:\n",
    "#     rez = parse(creation_time)\n",
    "# except ValueError:\n",
    "#     rez = 'default'\n",
    "# except OverflowError:\n",
    "#     rez = 'default'\n",
    "# rez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-09-24\n",
      "11:04:40\n",
      "11:04:40\n"
     ]
    }
   ],
   "source": [
    "print (rez.date())\n",
    "print(rez.time())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-26\n",
      "09:27:15.881532\n",
      "09:27:15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 1, 26, 9, 27, 15, 881532)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "dt = datetime.datetime.now()\n",
    "print(dt.date())\n",
    "print(dt.time())\n",
    "m = dt.strftime(\"%H:%M:%S\")\n",
    "print(m)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = spark.createDataFrame([Row(a=1, b=[1,2,3],c=[7,8,9], d='foo')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: long (nullable = true)\n",
      " |-- b: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- c: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- d: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 5.0 failed 1 times, most recent failure: Lost task 3.0 in stage 5.0 (TID 73, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$dfAssembleNoExtras$1: (string) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:389)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:148)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NullPointerException\n\tat com.johnsnowlabs.nlp.DocumentAssembler.com$johnsnowlabs$nlp$DocumentAssembler$$assemble(DocumentAssembler.scala:52)\n\tat com.johnsnowlabs.nlp.DocumentAssembler$$anonfun$dfAssembleNoExtras$1.apply(DocumentAssembler.scala:72)\n\tat com.johnsnowlabs.nlp.DocumentAssembler$$anonfun$dfAssembleNoExtras$1.apply(DocumentAssembler.scala:71)\n\t... 13 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$dfAssembleNoExtras$1: (string) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:389)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:148)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.NullPointerException\n\tat com.johnsnowlabs.nlp.DocumentAssembler.com$johnsnowlabs$nlp$DocumentAssembler$$assemble(DocumentAssembler.scala:52)\n\tat com.johnsnowlabs.nlp.DocumentAssembler$$anonfun$dfAssembleNoExtras$1.apply(DocumentAssembler.scala:72)\n\tat com.johnsnowlabs.nlp.DocumentAssembler$$anonfun$dfAssembleNoExtras$1.apply(DocumentAssembler.scala:71)\n\t... 13 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2a38182bfbe2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 5.0 failed 1 times, most recent failure: Lost task 3.0 in stage 5.0 (TID 73, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$dfAssembleNoExtras$1: (string) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:389)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:148)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.NullPointerException\n\tat com.johnsnowlabs.nlp.DocumentAssembler.com$johnsnowlabs$nlp$DocumentAssembler$$assemble(DocumentAssembler.scala:52)\n\tat com.johnsnowlabs.nlp.DocumentAssembler$$anonfun$dfAssembleNoExtras$1.apply(DocumentAssembler.scala:72)\n\tat com.johnsnowlabs.nlp.DocumentAssembler$$anonfun$dfAssembleNoExtras$1.apply(DocumentAssembler.scala:71)\n\t... 13 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2029)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2050)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2069)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:455)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$dfAssembleNoExtras$1: (string) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>>>)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIterator.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$8$$anon$1.hasNext(WholeStageCodegenExec.scala:395)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:389)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:148)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: java.lang.NullPointerException\n\tat com.johnsnowlabs.nlp.DocumentAssembler.com$johnsnowlabs$nlp$DocumentAssembler$$assemble(DocumentAssembler.scala:52)\n\tat com.johnsnowlabs.nlp.DocumentAssembler$$anonfun$dfAssembleNoExtras$1.apply(DocumentAssembler.scala:72)\n\tat com.johnsnowlabs.nlp.DocumentAssembler$$anonfun$dfAssembleNoExtras$1.apply(DocumentAssembler.scala:71)\n\t... 13 more\n"
     ]
    }
   ],
   "source": [
    "t1 = t.rdd\n",
    "t2 = t1.map(lambda x: x[0])\n",
    "t2.take(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Region for NLP Module: --> Non-working to RDD\n",
    "#Region for NLP Module: --> Non-working to RDD\n",
    "#Region for NLP Module: --> Non-working to RDD\n",
    "#Region for NLP Module: --> Non-working to RDD\n",
    "#Region for NLP Module: --> Non-working to RDD\n",
    "#Region for NLP Module: --> Non-working to RDD\n",
    "#Region for NLP Module: --> Non-working to RDD\n",
    "\n",
    "#spark-nlp pipeline --> each can be included in the data frame\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"tweet\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentence_detector = SentenceDetectorModel() \\\n",
    "    .setInputCols([\"document\"]) \\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = RegexTokenizer() \\\n",
    "    .setInputCols([\"sentence\"]) \\\n",
    "    .setOutputCol(\"token\")\n",
    "    \n",
    "normalizer = Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normalized_token\")     \n",
    "    \n",
    "lemmatizer = Lemmatizer() \\\n",
    "    .setInputCols([\"normalized_token\"]) \\\n",
    "    .setOutputCol(\"lemma\") \\\n",
    "    .setDictionary(resource_path+\"lemma-corpus/AntBNC_lemmas_ver_001.txt\")    \n",
    "          \n",
    "# sentiment analysis requires 2 arguments: lemman and sentence to determine \n",
    "# the context of that particular sentence\n",
    "sentiment_detector = SentimentDetectorModel() \\\n",
    "    .setInputCols([\"lemma\", \"sentence\"]) \\\n",
    "    .setOutputCol(\"sentiment_score\") \\\n",
    "    .setDictPath(resource_path+\"sentiment-corpus/default-sentiment-dict.txt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CleanAnnotation False to have columns of intermediate data column!    \n",
    "finisher_lemmatizer = Finisher() \\\n",
    "    .setInputCols([\"sentiment_score\"]) \\\n",
    "    .setOutputCols([\"sentiment_score\"])\\\n",
    "    .setCleanAnnotations(False)\\\n",
    "    .setIncludeKeys(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tid: long (nullable = true)\n",
      " |-- uid: long (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      " |-- creation_time: string (nullable = true)\n",
      " |-- time_zone: string (nullable = true)\n",
      " |-- followers_count: long (nullable = true)\n",
      " |-- friends_count: long (nullable = true)\n",
      " |-- city_name: string (nullable = true)\n",
      " |-- country_name: string (nullable = true)\n",
      " |-- media_ary: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- display_url: string (nullable = true)\n",
      " |    |    |-- expanded_url: string (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- id_str: string (nullable = true)\n",
      " |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- media_url: string (nullable = true)\n",
      " |    |    |-- media_url_https: string (nullable = true)\n",
      " |    |    |-- sizes: struct (nullable = true)\n",
      " |    |    |    |-- large: struct (nullable = true)\n",
      " |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |-- medium: struct (nullable = true)\n",
      " |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |-- small: struct (nullable = true)\n",
      " |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |    |-- thumb: struct (nullable = true)\n",
      " |    |    |    |    |-- h: long (nullable = true)\n",
      " |    |    |    |    |-- resize: string (nullable = true)\n",
      " |    |    |    |    |-- w: long (nullable = true)\n",
      " |    |    |-- source_status_id: long (nullable = true)\n",
      " |    |    |-- source_status_id_str: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- url: string (nullable = true)\n",
      " |-- hashtag_ary: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- indices: array (nullable = true)\n",
      " |    |    |    |-- element: long (containsNull = true)\n",
      " |    |    |-- text: string (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- document: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- sentence: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- token: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- normalized_token: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- lemma: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- annotatorType: string (nullable = true)\n",
      " |    |    |-- begin: integer (nullable = false)\n",
      " |    |    |-- end: integer (nullable = false)\n",
      " |    |    |-- result: string (nullable = true)\n",
      " |    |    |-- metadata: map (nullable = true)\n",
      " |    |    |    |-- key: string\n",
      " |    |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- sentiment_score: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Building 2 pipelines\n",
    "pipeline_lemmatizer = Pipeline(stages=[document_assembler, sentence_detector,tokenizer,\n",
    "                            normalizer, lemmatizer, sentiment_detector,\n",
    "                            finisher_lemmatizer])\n",
    "\n",
    "model = pipeline_lemmatizer.fit(main_df)\n",
    "nlp_df = model.transform(main_df)\n",
    "nlp_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
